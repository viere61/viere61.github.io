<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>基础反向传播（尚未更新数学原理）和机器学习五大分类</title>
    <link href="/2022/03/09/%E5%9F%BA%E7%A1%80%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88%E5%B0%9A%E6%9C%AA%E6%9B%B4%E6%96%B0%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%EF%BC%89%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%94%E5%A4%A7%E5%88%86%E7%B1%BB/"/>
    <url>/2022/03/09/%E5%9F%BA%E7%A1%80%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88%E5%B0%9A%E6%9C%AA%E6%9B%B4%E6%96%B0%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%EF%BC%89%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%94%E5%A4%A7%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p><strong>反向传播</strong>（英文Backpropagation，缩写BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会回馈给最佳化方法，用来更新权值以最小化损失函数。</p><p>反向传播要求有对每个输入值想得到的已知输出，来计算损失函数梯度。因此，它通常被认为是一种监督式学习方法。</p><p>我们可以将梯度下降法理解成general的优化算法，而反向传播则是其在神经网络上的具体实现方式。</p><p>我们的目标是，计算代价函数对于权重微小变化的敏感程度，</p><p>即，求代价函数对权重的导数。</p><p>即，改变权重对代价函数的值造成的变化。</p><p>这样我们就知道，如何调整w和b变量才可以使得代价函数下降最快。</p><p>拿单个样本中最后两个神经元来看，</p><p>代价函数之于一个样本是：</p><p>（预测值-最后一层神经元实际激活值）**2</p><p>最后一层神经元实际激活值 = 激活函数<em> （最后一层的权重</em>倒数第二层的激活值+最后一层的偏置）</p><p><img src="/Users/felix/viere/themes/fluid/source/img/20220309blog1.png" alt=""></p><p><img src="/Users/felix/viere/themes/fluid/source/img/20220309blog2.png" alt=""></p><p>倒数第二层的激活值 = 倒数第二层的权重*倒数第三层的激活值+倒数第二层的偏置</p><p><img src="/Users/felix/viere/themes/fluid/source/img/20220309blog3.png" alt=""></p><p>只有最后一层有激活函数</p><p>以此类推。</p><h2 id="机器学习五大分类"><a href="#机器学习五大分类" class="headerlink" title="机器学习五大分类"></a>机器学习五大分类</h2><p><strong>监督学习：</strong></p><p>从给定的训练集中学习一个函数，当新数据到来时，可以根据这个函数来预测结果。监督学习的训练集要求有输入和输出，也称之为特征和目标。从输入数据提取数据特征，以达到输出特定目标的目的。训练集的目标是由人标注的，常见的监督学习算法包括回归和分类</p><p><strong>无监督学习：</strong></p><p>无监督学习与监督学习相比，训练集没有人为标注的结果（有些数据难以人工标注分类或标注分类成本太高）。无监督学习的典型学习算法是聚类（将相似的东西聚在一起，而不关心这一类是什么）。</p><p><strong>半监督学习：</strong></p><p>半监督学习是一种基于监督学习和无监督学习之间的方法。半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。</p><p><strong>迁移学习：</strong></p><p>将在一个模型中已经训练好的模型参数迁移到新的模型继续训练学习的学习方法。</p><p><strong>增强学习：</strong></p><p>通过观察周围环境来学习。每个动作都会对环境有所影响，学习对象根据观察周围环境的反馈来做出判断。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归，最小二乘法，损失函数的杂乱介绍</title>
    <link href="/2021/12/16/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%8C%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E6%9D%82%E4%B9%B1%E4%BB%8B%E7%BB%8D/"/>
    <url>/2021/12/16/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%8C%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E6%9D%82%E4%B9%B1%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<p>最小二乘是很多东西的核心 比如 $x = 5,6,7, y = 10,18,28$， 如果<script type="math/tex">x=10</script>，$y$是多少 这种就是用最小二乘来建模 求出这个背后的规律 $y=x^2-3x$</p><p>给定数据集 $D = \lbrace(\boldsymbol{x}^{(1)}, y^{(1)}), (\boldsymbol{x}^{(2)}, y^{(2)}), … ,(\boldsymbol{x}^{(m)}, y^{(m)})\rbrace$ ，数据集中有m个数据对。预测函数会根据输入特征x来计算输出值h(x)。其输入和输出的函数关系如下：</p><p>$h_\theta=\theta_0+\theta_1x$</p><p>实质上它和我们中学时解决数学问题时常用的$y=ax+b$方程并没有差别。方程描述了变量$y$随着变量$x$而变化。方程从图形上来看，是一条直线。如果建立好这样的数学模型，已知$x$我们就可以得到预测的$\hat{y}$(y hat)了。统计学家给变量带上了一个小帽子，表示这是预测值，以区别于真实观测到的数据，即真实值$y$(Label)。</p><p>方程只有一个自变量$x$，且不含平方立方等非一次项，因此被称为<strong>一元线性方程</strong>。</p><p><img src="http://aixingqiu-1258949597.cos.ap-beijing.myqcloud.com/2020-05-20-035625.png" alt=""></p><p><em>所示是解释房屋面积对于房价影响的散点图</em></p><p><strong>以上是之于统计学的简单理解。以神经网络作为出发点，线性回归（Linear Regression），即拟合直线的过程，也是极其重要的概念。</strong></p><p>打个比方。利用神经网络，AI判断图像是猫与否。在这儿，我们给输入层输入了多张人眼判断过是猫与否的图片（真实值y），经过神经网络隐藏层（中间层）的判断，再在输出层输出预测值y hat作为结果。</p><p>$y_i\in\left\{0,1\right\}$，即0和1代表着是不是猫和是猫。</p><p>假设y hat的激活函数为Sigmoid函数，那，</p><p>${\hat{y}_i}$ ~ $\left\{0,1\right\}$，靠近0代表着倾向于不是猫，靠近1代表着倾向于是猫。</p><p>ps神经网络有参数$w$和$b$ (bias)，但本文不讨论神经网络的参数体系。</p><p>另一个极重要的概念是<strong>损失函数（Loss Function）</strong>。</p><p>损失函数（Loss Function ）是定义在单个样本上的，算的是一个样本的误差。<strong>代价函数（Cost Function ）</strong>是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。</p><p>统计学家通常用$L(\hat{y},y)$表示损失函数（还有一种表达则是将其中$L$替换成$J$）。损失函数代表预测值和真实值之间的差异程度，可用来判断机器预测值和真实值得误差。</p><p>一般来说训练机器学习的目的就是希望将损失函数减到最小。</p><p>下面的公式代表单个样本点上预测值与真实值的误差的平方。</p><p>$L\left(\hat{y}^\left(i\right),y^\left(i\right)\right)=\left(\hat{y}^\left(i\right)−y^\left(i\right)\right)^2$</p><p>这里并非取$\left(\hat{y}−y^\left(i\right)\right)$的绝对值而是取平方一部分的原因是开平方后全程可导，且并不影响求误差目的本身。</p><p>将数据集的所有误差求和取平均…</p><p>$L(\hat{y},y)=$1/2$m$$\sum\limits_{i=1}^m\left(\hat{y}^\left(i\right)−y^\left(i\right)\right)^2$</p><p>取最小…</p><p>$\min\sum\limits_{i=1}^m\left(\hat{y}^\left(i\right)−y^\left(i\right)\right)^2$</p><p><em>到这一步，应该能明白：开平方即最小二乘法的“二乘”，取最小值，也就是当人脑判断和机器判断之间误差最小时，即“最小”。最小二乘法的本质是均方误差的最小化。</em></p><p>下面是Prof Andrew在Coursera课程ML中给出的以最小二乘法来求损失函数的式子…</p><p><script type="math/tex">L(\hat{y},y)=</script>1/2$(\hat{y},y)^2$</p><p>上面公式出现的1/2单纯为了求导方便。这个公式没有连加符号，因为图片是一张一张训练的。</p><p><img src="http://aixingqiu-1258949597.cos.ap-beijing.myqcloud.com/2020-05-20-035618.png" alt=""></p><p><em>假设直线如图，误差的方差和相对大</em></p><p><img src="http://aixingqiu-1258949597.cos.ap-beijing.myqcloud.com/2020-05-20-035613.png" alt=""></p><p><em>假设直线如图，误差的方差和相对小</em></p>]]></content>
    
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解释激活函数之于神经网络</title>
    <link href="/2021/12/14/%E8%A7%A3%E9%87%8A%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B9%8B%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2021/12/14/%E8%A7%A3%E9%87%8A%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B9%8B%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="激活函数是什么"><a href="#激活函数是什么" class="headerlink" title="激活函数是什么"></a>激活函数是什么</h2><p>所谓激活函数（Activation Function），就是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。激活函数对于人工神经网络模型去学习、理解非常复杂和非线性的函数来说具有十分重要的作用。它们将非线性特性引入到我们的网络中。如图，在神经元中，输入（inputs）通过加权，求和后，还被作用在一个函数上，这个函数就是激活函数。</p><p><img src="/img/v2-b50b34f6c48a49968de2d7b6de79b7e6_b.png"></p><h2 id="为什么用激活函数"><a href="#为什么用激活函数" class="headerlink" title="为什么用激活函数"></a>为什么用激活函数</h2><p>激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，应用到众多的非线性模型中，解决非线性问题。</p><p>无激活函数的二分问题增加再多感知机（Perceptron）都只是矩阵相乘。因为其本质是在上层输入线型函数，输出线性组合，无非线性因素。将面临的问题以下图为例。</p><p><img src="/img/%E7%BA%BF%E6%80%A7%E4%B8%8D%E5%8F%AF%E5%88%86.png"></p><p>加入阶跃函数后，如下图。阶跃函数即小于0不激活分到0，大于0被激活分到1（100%）。在机器学习的划分时，它意味着划分的边界。</p><p><img src="/img/%E5%8A%A0%E5%85%A5%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0.png"></p><p>显然阶跃函数不是神经网络中一个完美的选择，我们希望它可以是0%到100%里的任意值。值越大，激活程度越高。对于分类，也意味着它属于这一类的概率越大。其中一个选择是加入Sigmoid函数作为激活函数。</p><p><img src="https://gblobscdn.gitbook.com/assets%2F-LAHBpdrwoD-M1bqEq-u%2F-LJhU4NN2a_jPOdMmwT0%2F-LJhU6EDYTuuYCHiJR48%2Factivation-function.png?alt=media"></p><p>加入Sigmoid函数后。加入非线性因素。</p><p><img src="/img/%E5%8A%A0%E5%85%A5Sigmoid%E5%87%BD%E6%95%B0.png"></p><p>其他常用激活函数有Tanh，ReLU，Leaky，ReLU，PReLU，ELU，Maxout。因为每个激活函数都要考虑输入输出以及数据变化所以要谨慎选择。因为本人能力有限，本文不会对它们的区别作出解释。</p><p><img src="/img/v2-17708ef17113fc120b045db3de3dbaac_b.jpg"></p><h2 id="利用GeoGebra模拟"><a href="#利用GeoGebra模拟" class="headerlink" title="利用GeoGebra模拟"></a>利用GeoGebra模拟</h2><p>无激活函数。</p><p><img src="/img/%E6%97%A0%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png"></p><p>加入阶跃函数。</p><p><img src="/img/%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0.png"></p><p>加入Sigmoid函数。</p><p><img src="/img/Sigmoid%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/12/13/hello-world/"/>
    <url>/2021/12/13/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
